@article{Meintjes2012,
abstract = {Summary: The two main functions of bioinformatics are the organization and analysis of biological data using computational resources. Geneious Basic has been designed to be an easy- to-use and flexible desktop software application framework for the organization and analysis of biological data, with a focus on molecular sequences and related data types. It integrates numerous industry-standard discovery analysis tools, with interactive visualizations to generate publication-ready images. One key contribution to researchers in the life sciences is the Geneious public application programming interface (API) that affords the ability to leverage the existing framework of the Geneious Basic software platform for virtually unlimited extension and customization. The result is an increase in the speed and quality of development of computation tools for the life sciences, due to the functionality and graphical user interface available to the developer through the public API. Geneious Basic represents an ideal platform for the bioinformatics community to leverage existing components and to integrate their own specific requirements for the discovery, analysis and visualization of biological data. Availability and implementation: Binaries and public API freely available for download at http://www.geneious.com/basic, implemented in Java and supported on Linux, Apple OSX and MS Windows. The software is also available from the Bio-Linux package repository at http://nebc.nerc.ac.uk/news/geneiousonbl. Contact: peter@biomatters.com Received},
author = {Meintjes, P. and Kearse, Matthew and Moir, Richard and Wilson, Amy and Stones-Havas, Steven and Cheung, Matthew and Sturrock, Shane and Buxton, Simon and Cooper, Alex and Markowitz, Sidney and Duran, Chris and Thierer, Tobias and Asthon, Bruce and Meintjes, Peter and Drummond, Alexei J},
doi = {10.1093/bioinformatics/bts199},
file = {:home/vojta/dokumenty/clanky/pdf/Kearse\_etal\_2012\_Geneious\_Basic-integrated\_and\_extendable\_desktop\_software\_platform\_for\_organization\_and\_anal\_of\_seq\_data.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
month = apr,
number = {12},
pages = {1647--1649},
title = {{Geneious Basic: An integrated and extendable desktop software platform for the organization and analysis of sequence data}},
url = {http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/bts199},
volume = {28},
year = {2012}
}

@article{Kent2002,
abstract = {Analyzing vertebrate genomes requires rapid mRNA/DNA and cross-species protein alignments. A new tool, BLAT, is more accurate and 500 times faster than popular existing tools for mRNA/DNA alignments and 50 times faster for protein alignments at sensitivity settings typically used when comparing vertebrate sequences. BLAT’s speed stems from an index of all nonoverlapping K-mers in the genome. This index fits inside the RAM of inexpensive computers, and need only be computed once for each genome assembly. BLAT has several major stages. It uses the index to find regions in the genome likely to be homologous to the query sequence. It performs an alignment between homologous regions. It stitches together these aligned regions (often exons) into larger alignments (typically genes). Finally, BLAT revisits small internal exons possibly missed at the first stage and adjusts large gap boundaries that have canonical splice sites where feasible. This paper describes how BLAT was optimized. Effects on speed and sensitivity are explored for various K-mer sizes, mismatch schemes, and number of required index matches. BLAT is compared with other alignment programs on various test sets and then used in several genome-wide applications. http://genome.ucsc.edu hosts a web-based BLAT server for the human genome.},
author = {Kent, W James},
doi = {10.1101/gr.229202.},
file = {:home/vojta/dokumenty/clanky/pdf/Kent\_2002\_BLAT-BLAST-Like\_Alignment\_Tool.pdf:pdf},
issn = {1088-9051},
journal = {Genome research},
pages = {656--664},
title = {{BLAT — The BLAST -Like Alignment Tool}},
url = {http://genome.cshlp.org/content/12/4/656.short},
volume = {12},
year = {2002}
}

@article{Langmead2012,
abstract = {As the rate of sequencing increases, greater throughput is demanded from read aligners. The full-text minute index is often used to make alignment very fast and memory-efficient, but the approach is ill-suited to finding longer, gapped alignments. Bowtie 2 combines the strengths of the full-text minute index with the flexibility and speed of hardware-accelerated dynamic programming algorithms to achieve a combination of high speed, sensitivity and accuracy.},
author = {Langmead, Ben and Salzberg, Steven L},
issn = {1548-7091},
journal = {Nature Methods},
month = apr,
number = {4},
pages = {357--359},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
title = {{Fast gapped-read alignment with Bowtie 2}},
url = {http://dx.doi.org/10.1038/nmeth.1923 10.1038/nmeth.1923 http://www.nature.com/nmeth/journal/v9/n4/abs/nmeth.1923.html\#supplementary-information},
volume = {9},
year = {2012}
}

@article{Li2001,
abstract = {Summary: We present a fast and flexible program for clustering large protein databases at different sequence identity levels. It takes less than 2 h for the all-against-all sequence comparison and clustering of the non-redundant protein database of over 560000 sequences on a high-end PC. The output database, including only the representative sequences, can be used for more efficient and sensitive database searches. Availability: The program is available from http: //bioinformatics.burnham-inst.org/cd-hi Contact: liwz@sdsc.edu or adam@burnham-inst.org},
author = {Li, Weizhong and Jaroszewski, Lukasz and Godzik, Adam},
doi = {10.1093/bioinformatics/17.3.282},
file = {:home/vojta/dokumenty/clanky/pdf/Li\_etal\_2001\_Clustering\_of\_highly\_homologous\_sequences\_to\_reduce\_the\_size\_of\_large\_protein\_databases.pdf:pdf},
isbn = {3900051070},
journal = {Bioinformatics (Oxford, England)},
number = {3},
pages = {282--283},
title = {{Clustering of highly homologous sequences to reduce the size of large protein databases}},
url = {http://bioinformatics.oxfordjournals.org/content/17/3/282.short},
volume = {17},
year = {2001}
}

@article{Li2002,
abstract = {MOTIVATION: Sequence clustering replaces groups of similar sequences in a database with single representatives. Clustering large protein databases like the NCBI Non-Redundant database (NR) using even the best currently available clustering algorithms is very time-consuming and only practical at relatively high sequence identity thresholds. Our previous program, CD-HI, clustered NR at 90\% identity in approximately 1 h and at 75\% identity in approximately 1 day on a 1 GHz Linux PC (Li et al., Bioinformatics, 17, 282, 2001); however even faster clustering speed is needed because the size of protein databases are rapidly growing and many applications desire a lower attainable thresholds. RESULTS: For our previous algorithm (CD-HI), we have employed short-word filters to speed up the clustering. In this paper, we show that tolerating some redundancy makes for more efficient use of these short-word filters and increases the program's speed 100 times. Our new program implements this technique and clusters NR at 70\% identity within 2 h, and at 50\% identity in approximately 5 days. Although some redundancy is present after clustering, our new program's results only differ from our previous program's by less than 0.4\%.},
author = {Li, Weizhong and Jaroszewski, Lukasz and Godzik, Adam},
doi = {10.1093/bioinformatics/18.1.77},
file = {:home/vojta/dokumenty/clanky/pdf/Li\_etal\_2002\_Tolerating\_some\_redundancy\_significantly\_speeds\_up\_clustering\_of\_large\_protein\_databases.pdf:pdf},
isbn = {1367-4803 (Print)$\backslash$r1367-4803 (Linking)},
issn = {1367-4803},
journal = {Bioinformatics (Oxford, England)},
number = {1},
pages = {77--82},
pmid = {11836214},
title = {{Tolerating some redundancy significantly speeds up clustering of large protein databases.}},
url = {http://bioinformatics.oxfordjournals.org/content/18/1/77.short},
volume = {18},
year = {2002}
}

@article{Li2006,
abstract = {MOTIVATION: In 2001 and 2002, we published two papers (Bioinformatics, 17, 282-283, Bioinformatics, 18, 77-82) describing an ultrafast protein sequence clustering program called cd-hit. This program can efficiently cluster a huge protein database with millions of sequences. However, the applications of the underlying algorithm are not limited to only protein sequences clustering, here we present several new programs using the same algorithm including cd-hit-2d, cd-hit-est and cd-hit-est-2d. Cd-hit-2d compares two protein datasets and reports similar matches between them; cd-hit-est clusters a DNA/RNA sequence database and cd-hit-est-2d compares two nucleotide datasets. All these programs can handle huge datasets with millions of sequences and can be hundreds of times faster than methods based on the popular sequence comparison and database search tools, such as BLAST.},
author = {Li, Weizhong and Godzik, Adam},
doi = {10.1093/bioinformatics/btl158},
file = {:home/vojta/dokumenty/clanky/pdf/Li\_et\_Godzik\_2006\_Cd-hit-fast\_program\_for\_clustering\_and\_comparing\_large\_sets\_of\_protein\_or\_nucleotide\_sequences.pdf:pdf},
isbn = {1367-4803 (Print)$\backslash$n1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {13},
pages = {1658--1659},
pmid = {16731699},
title = {{Cd-hit: A fast program for clustering and comparing large sets of protein or nucleotide sequences}},
url = {http://bioinformatics.oxfordjournals.org/content/22/13/1658.short},
volume = {22},
year = {2006}
}

@article{Fu2012,
abstract = {CD-HIT is a widely used program for clustering biological sequences to reduce sequence redundancy and improve the performance of other sequence analyses. In response to the rapid increase in the amount of sequencing data produced by the next-generation sequencing technologies, we have developed a new CD-HIT program accelerated with a novel parallelization strategy and some other techniques to allow efficient clustering of such datasets. Our tests demonstrated very good speedup derived from the parallelization for up to ∼24 cores and a quasi-linear speedup for up to ∼8 cores. The enhanced CD-HIT is capable of handling very large datasets in much shorter time than previous versions.},
author = {Fu, Limin and Niu, Beifang and Zhu, Zhengwei and Wu, Sitao and Li, Weizhong},
doi = {10.1093/bioinformatics/bts565},
file = {:home/vojta/dokumenty/clanky/pdf/Fu\_etal\_2012\_CD-HIT-accelerated\_for\_clustering\_the\_next-generation\_sequencing\_data.pdf:pdf},
isbn = {1367-4811 (Electronic)$\backslash$n1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {23},
pages = {3150--3152},
pmid = {23060610},
title = {{CD-HIT: Accelerated for clustering the next-generation sequencing data}},
url = {http://bioinformatics.oxfordjournals.org/content/28/23/3150.short},
volume = {28},
year = {2012}
}

@article{Huang2010,
abstract = {Summary: CD-HIT is a widely used program for clustering and comparing large biological sequence datasets. In order to further assist the CD-HIT users, we significantly improved this program with more functions and better accuracy, scalability and flexibility. Most importantly, we developed a new web server, CD-HIT Suite, for clustering a user-uploaded sequence dataset or comparing it to another dataset at different identity levels. Users can now interactively explore the clusters within web browsers. We also provide downloadable clusters for several public databases (NCBI NR, Swissprot and PDB) at different identity levels. Availability: Free access at http://cd-hit.org Contact: liwz@sdsc.edu Supplementary information: Supplementary data are available at Bioinformatics online. Received},
author = {Huang, Y. and Niu, B. and Gao, Y. and Fu, L. and Li, W.},
doi = {10.1093/bioinformatics/btq003},
file = {:home/vojta/dokumenty/clanky/pdf/Huang\_etal\_2010\_CD-HIT\_Suite-web\_server\_for\_clustering\_and\_comparing\_biological\_sequences.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
number = {5},
pages = {680--682},
title = {{CD-HIT Suite: a web server for clustering and comparing biological sequences}},
url = {http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/btq003},
volume = {26},
year = {2010}
}

@article{Niu2010,
abstract = {BACKGROUND: Artificial duplicates from pyrosequencing reads may lead to incorrect interpretation of the abundance of species and genes in metagenomic studies. Duplicated reads were filtered out in many metagenomic projects. However, since the duplicated reads observed in a pyrosequencing run also include natural (non-artificial) duplicates, simply removing all duplicates may also cause underestimation of abundance associated with natural duplicates. RESULTS: We implemented a method for identification of exact and nearly identical duplicates from pyrosequencing reads. This method performs an all-against-all sequence comparison and clusters the duplicates into groups using an algorithm modified from our previous sequence clustering method cd-hit. This method can process a typical dataset in approximately 10 minutes; it also provides a consensus sequence for each group of duplicates. We applied this method to the underlying raw reads of 39 genomic projects and 10 metagenomic projects that utilized pyrosequencing technique. We compared the occurrences of the duplicates identified by our method and the natural duplicates made by independent simulations. We observed that the duplicates, including both artificial and natural duplicates, make up 4-44\% of reads. The number of natural duplicates highly correlates with the samples' read density (number of reads divided by genome size). For high-complexity metagenomic samples lacking dominant species, natural duplicates only make up <1\% of all duplicates. But for some other samples like transcriptomic samples, majority of the observed duplicates might be natural duplicates. CONCLUSIONS: Our method is available from http://cd-hit.org as a downloadable program and a web server. It is important not only to identify the duplicates from metagenomic datasets but also to distinguish whether they are artificial or natural duplicates. We provide a tool to estimate the number of natural duplicates according to user-defined sample types, so users can decide whether to retain or remove duplicates in their projects.},
author = {Niu, Beifang and Fu, Limin and Sun, Shulei and Li, Weizhong},
doi = {10.1186/1471-2105-11-187},
file = {:home/vojta/dokumenty/clanky/pdf/Niu\_etal\_2010\_Artificial\_and\_natural\_duplicates\_in\_pyrosequencing\_reads\_of\_metagenomic\_data.pdf:pdf},
isbn = {1471-2105 (Electronic)$\backslash$r1471-2105 (Linking)},
issn = {1471-2105},
journal = {BMC bioinformatics},
pages = {187},
pmid = {20388221},
title = {{Artificial and natural duplicates in pyrosequencing reads of metagenomic data.}},
volume = {11},
year = {2010}
}

@article{Li2012b,
abstract = {The rapid advances of high-throughput sequencing technologies dramatically prompted metagenomic studies of microbial communities that exist at various environments. Fundamental questions in metagenomics include the identities, composition and dynamics of microbial populations and their functions and interactions. However, the massive quantity and the comprehensive complexity of these sequence data pose tremendous challenges in data ana- lysis. These challenges include but are not limited to ever-increasing computational demand, biased sequence sam- pling, sequence errors, sequence artifacts and novel sequences. Sequence clustering methods can directly answer many of the fundamental questions by grouping similar sequences into families. In addition, clustering analysis also addresses the challenges in metagenomics. Thus, a large redundant data set can be represented with a small non-redundant set, where each cluster can be represented by a single entry or a consensus. Artifacts can be rapidly detected through clustering. Errors can be identified, filtered or corrected by using consensus from sequences within clusters.},
author = {Li, W. and Fu, L. and Niu, B. and Wu, S. and Wooley, J.},
doi = {10.1093/bib/bbs035},
file = {:home/vojta/dokumenty/clanky/pdf/Li\_etal\_2012\_Ultrafast\_clustering\_algorithms\_for\_metagenomic\_sequence\_analysis.pdf:pdf},
issn = {1467-5463},
journal = {Briefings in Bioinformatics},
keywords = {OTU,artificial duplicates,clustering,metagenomics,next-generation sequencing,protein families},
mendeley-tags = {clustering,metagenomics,next-generation sequencing,protein families,artificial duplicates,OTU},
number = {6},
pages = {656--668},
title = {{Ultrafast clustering algorithms for metagenomic sequence analysis}},
url = {http://bib.oxfordjournals.org/cgi/doi/10.1093/bib/bbs035},
volume = {13},
year = {2012}
}

@misc{Gordon2010,
abstract = {The FASTX-Toolkit is a collection of command line tools for Short-Reads FASTA/FASTQ files preprocessing.},
author = {Gordon and Hannon},
title = {{FASTX-Toolkit. FASTQ/A short-reads pre-processing tools}},
url = {http://hannonlab.cshl.edu/fastx\_toolkit/},
year = {2010}
}

@article{Magoc2011,
abstract = {Motivation: Next-generation sequencing technologies generate very large numbers of short reads. Even with very deep genome coverage, short read lengths cause problems in de novo assemblies. The use of paired-end libraries with a fragment size shorter than twice the read length provides an opportunity to generate much longer reads by overlapping and merging read pairs before assembling a genome. Results: We present FLASH, a fast computational tool to extend the length of short reads by overlapping paired-end reads from fragment libraries that are sufficiently short. We tested the correctness of the tool on one million simulated read pairs, and we then applied it as a pre-processor for genome assemblies of Illumina reads from the bacterium Staphylococcus aureus and human chromosome 14. FLASH correctly extended and merged reads >99\% of the time on simulated reads with an error rate of <1\%. With adequately set parameters, FLASH correctly merged reads over 90\% of the time even when the reads contained up to 5\% errors. When FLASH was used to extend reads prior to assembly, the resulting assemblies had substantially greater N50 lengths for both contigs and scaffolds. Availability and Implementation: The FLASH system is implemented in C and is freely available as open-source code at http://www.cbcb.umd.edu/software/flash. Contact: t.magoc@gmail.com},
author = {Magoc, T. and Salzberg, S. L.},
doi = {10.1093/bioinformatics/btr507},
file = {:home/vojta/dokumenty/clanky/pdf/Magoc\_et\_Salzberg\_2011\_FLASH-fast\_length\_adjustment\_of\_short\_reads\_to\_improve\_genome\_assemblies.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
number = {21},
pages = {2957--2963},
title = {{FLASH: fast length adjustment of short reads to improve genome assemblies}},
url = {http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/btr507},
volume = {27},
year = {2011}
}

@article{Li2009,
abstract = {SUMMARY: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. AVAILABILITY: http://samtools.sourceforge.net.},
author = {Li, Heng and Handsaker, Bob and Wysoker, Alec and Fennell, Tim and Ruan, Jue and Homer, Nils and Marth, Gabor and Abecasis, Goncalo and Durbin, Richard and Subgroup, 1000 Genome Project Data Processing},
doi = {10.1093/bioinformatics/btp352},
file = {:home/vojta/dokumenty/clanky/pdf/Li\_etal\_2009\_Sequence\_Alignment-Map\_format\_and\_SAMtools.pdf:pdf},
isbn = {1367-4803$\backslash$r1460-2059},
issn = {1367-4811},
journal = {Bioinformatics},
number = {16},
pages = {2078--2079},
pmid = {19505943},
title = {{The Sequence Alignment/Map format and SAMtools}},
url = {http://bioinformatics.oxfordjournals.org/cgi/content/full/25/16/2078},
volume = {25},
year = {2009}
}

@article{Li2011,
abstract = {Motivation: Most existing methods for DNA sequence analysis rely on accurate sequences or genotypes. However, in applications of the next-generation sequencing (NGS), accurate genotypes may not be easily obtained (e.g. multi-sample low-coverage sequencing or somatic mutation discovery). These applications press for the development of new methods for analyzing sequence data with uncertainty. Results: We present a statistical framework for calling SNPs, discovering somatic mutations, inferring population genetical parameters and performing association tests directly based on sequencing data without explicit genotyping or linkage-based imputation. On real data, we demonstrate that our method achieves comparable accuracy to alternative methods for estimating site allele count, for inferring allele frequency spectrum and for association mapping. We also highlight the necessity of using symmetric datasets for finding somatic mutations and confirm that for discovering rare events, mismapping is frequently the leading source of errors. Availability: http://samtools.sourceforge.net Contact: hengli@broadinstitute.org},
author = {Li, H.},
doi = {10.1093/bioinformatics/btr509},
file = {:home/vojta/dokumenty/clanky/pdf/Li\_2009\_statistical\_framework\_for\_SNP\_calling\_mutation\_discovery\_association\_mapping\_and\_population\_genetical\_parameter\_estimation\_from\_sequencing\_data.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
number = {21},
pages = {2987--2993},
title = {{A statistical framework for SNP calling, mutation discovery, association mapping and population genetical parameter estimation from sequencing data}},
url = {http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/btr509},
volume = {27},
year = {2011}
}

@article{Li2011a,
abstract = {Summary: I propose a new application of profile Hidden Markov Models in the area of SNP discovery from resequencing data, to greatly reduce false SNP calls caused by misalignments around insertions and deletions (indels). The central concept is per-Base Alignment Quality, which accurately measures the probability of a read base being wrongly aligned. The effectiveness of BAQ has been positively confirmed on large datasets by the 1000 Genomes Project analysis subgroup. Availability: http://samtools.sourceforge.net Contact: hengli@broadinstitute.org},
author = {Li, H.},
doi = {10.1093/bioinformatics/btr076},
file = {:home/vojta/dokumenty/clanky/pdf/Li\_2011\_Improving\_SNP\_discovery\_by\_base\_alignment\_quality.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
number = {8},
pages = {1157--1158},
title = {{Improving SNP discovery by base alignment quality}},
url = {http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/btr076},
volume = {27},
year = {2011}
}

@article{Straub2012,
abstract = {Premise of the study: Just as Sanger sequencing did more than 20 years ago, next-generation sequencing (NGS) is poised to revolutionize plant systematics. By combining multiplexing approaches with NGS throughput, systematists may no longer need to choose between more taxa or more characters. Here we describe a genome skimming (shallow sequencing) approach for plant systematics. • Methods: Through simulations, we evaluated optimal sequencing depth and performance of single-end and paired-end short read sequences for assembly of nuclear ribosomal DNA (rDNA) and plastomes and addressed the effect of divergence on reference-guided plastome assembly. We also used simulations to identify potential phylogenetic markers from low-copy nuclear loci at different sequencing depths. We demonstrated the utility of genome skimming through phylogenetic analysis of the Sonoran Desert clade (SDC) of Asclepias (Apocynaceae). • Key results: Paired-end reads performed better than single-end reads. Minimum sequencing depths for high quality rDNA and plastome assemblies were 40 × and 30 × , respectively. Divergence from the reference signifi cantly affected plastome assembly, but relatively similar references are available for most seed plants. Deeper rDNA sequencing is necessary to characterize intragenomic polymorphism. The low-copy fraction of the nuclear genome was readily surveyed, even at low sequencing depths. Nearly 160 000 bp of sequence from three organelles provided evidence of phylogenetic incongruence in the SDC. • Conclusions: Adoption of NGS will facilitate progress in plant systematics, as whole plastome and rDNA cistrons, partial mitochondrial genomes, and low-copy nuclear markers can now be effi ciently obtained for molecular phylogenetics studies.},
author = {Straub, Shannon C K and Parks, Matthew and Weitemier, Kevin and Fishbein, Mark and Cronn, Richard C and Liston, Aaron},
doi = {10.3732/ajb.1100335},
file = {:home/vojta/dokumenty/clanky/pdf/Straub\_etal\_2012\_Navigating\_tip\_of\_genomic\_iceberg-next-gen\_seq\_for\_plant\_syst.pdf:pdf},
issn = {1537-2197},
journal = {American journal of botany},
keywords = {Asclepias,Illumina,asclepias,chloroplast content,classify plant diversity,dna,for almost two decades,gene,genome skimming,illumina,low-copy nuclear,low-copy nuclear gene,next-generation sequencing,plant systematics,plant systematists have used,plastome,reference-guided assembly,ribosomal DNA cistron,ribosomal dna cistron,sequences to characterize and,these},
mendeley-tags = {Asclepias,Illumina,chloroplast content,genome skimming,low-copy nuclear gene,next-generation sequencing,plant systematics,plastome,reference-guided assembly,ribosomal DNA cistron},
month = feb,
number = {2},
pages = {349--64},
pmid = {22174336},
title = {{Navigating the tip of the genomic iceberg: Next-generation sequencing for plant systematics.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22174336},
volume = {99},
year = {2012}
}

@article{Matasci2014,
abstract = {The 1,000 plants (1KP) project is an international multi-disciplinary consortium that has generated transcriptome data from over 1,000 plant species, with exemplars for all of the major lineages across the Viridiplantae (green plants) clade. Here, we describe how to access the data used in a phylogenomics analysis of the first 85 species, and how to visualize our gene and species trees. Users can develop computational pipelines to analyse these data, in conjunction with data of their own that they can upload. Computationally estimated protein-protein interactions and biochemical pathways can be visualized at another site. Finally, we comment on our future plans and how they fit within this scalable system for the dissemination, visualization, and analysis of large multi-species data sets.},
author = {Matasci, Naim and Hung, Ling-Hong and Yan, Zhixiang and Carpenter, Eric J and Wickett, Norman J and Mirarab, Siavash and Nguyen, Nam and Warnow, Tandy and Ayyampalayam, Saravanaraj and Barker, Michael and Burleigh, J and Gitzendanner, Matthew a and Wafula, Eric and Der, Joshua P and DePamphilis, Claude W and Roure, B\'{e}atrice and Philippe, Herv\'{e} and Ruhfel, Brad R and Miles, Nicholas W and Graham, Sean W and Mathews, Sarah and Surek, Barbara and Melkonian, Michael and Soltis, Douglas E and Soltis, Pamela S and Rothfels, Carl and Pokorny, Lisa and Shaw, Jonathan a and DeGironimo, Lisa and Stevenson, Dennis W and Villarreal, Juan and Chen, Tao and Kutchan, Toni M and Rolf, Megan and Baucom, Regina S and Deyholos, Michael K and Samudrala, Ram and Tian, Zhijian and Wu, Xiaolei and Sun, Xiao and Zhang, Yong and Wang, Jun and Leebens-Mack, Jim and Wong, Gane Ka-Shu},
doi = {10.1186/2047-217X-3-17},
file = {:home/vojta/dokumenty/clanky/pdf/Matasci\_etal\_2014\_Data\_access\_for\_1000\_Plants-1KP-project.pdf:pdf},
issn = {2047-217X},
journal = {GigaScience},
keywords = {Biodiversity,Interactions,Pathways,Phylogenomics,Transcriptomes,Viridiplantae},
mendeley-tags = {Viridiplantae,Biodiversity,Transcriptomes,Phylogenomics,Interactions,Pathways},
number = {1},
pages = {17},
title = {{Data access for the 1,000 Plants (1KP) project}},
url = {http://www.gigasciencejournal.com/content/3/1/17},
volume = {3},
year = {2014}
}

